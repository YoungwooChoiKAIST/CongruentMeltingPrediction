{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import shap\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_score, recall_score, f1_score\n",
    "import xgboost\n",
    "\n",
    "font = {'weight' : 'bold',\n",
    "        'size'   : 14}\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation function\n",
    "\n",
    "def modelEvaluation(X_test, y_test, model):\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"        Accuracy: {:.3f}\".format(model.score(X_test, y_test)))\n",
    "    print(\" Precision score: {:.3f}\".format(precision_score(y_test, y_pred)))\n",
    "    print(\"    Recall score: {:.3f}\".format(recall_score(y_test, y_pred)))\n",
    "    print(\"        F1 score: {:.3f}\".format(f1_score(y_test, y_pred, average='weighted')))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom progress callback function\n",
    "\n",
    "def custom_progress_callback(estimator, params, mean_test_score, std_test_score):\n",
    "    print(f\"Hyperparameters: {params}\")\n",
    "    print(f\"Mean Test Score: {mean_test_score}\")\n",
    "    print(f\"Standard Deviation: {std_test_score}\")\n",
    "    print(\"-------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "\n",
    "db = pd.read_csv(\"data.csv\")\n",
    "reacdb = db[(db['Melting']==1)]\n",
    "\n",
    "reacdb = reacdb.sample(frac=1).reset_index(drop=True)\n",
    "y = reacdb['Congruency']\n",
    "X = reacdb.loc[:, 'Composition':'Angle sdev_dif'].astype('float')\n",
    "X = pd.DataFrame(StandardScaler().fit(X).transform(X), columns = X.columns)\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "feature_names = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data verification\n",
    "\n",
    "print(f\"Target binary compounds: {(db[db['CommonPair']==1].shape[0])}\")\n",
    "print(f\"Melting system: {(db[db['Melting']==1].shape[0])}\")\n",
    "print(f\"Coungruent melting compound: {(db[db['Congruency']==1].shape[0])}\")\n",
    "print(f\"Application compounds: {(db[db['CommonPair']==0].shape[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, test set split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "param_test = {\n",
    "    'max_depth':range(3,11,3),\n",
    "    'min_child_weight':range(1,11,2),\n",
    "    'gamma':[i/10.0 for i in range(0,6)],\n",
    "    'subsample':[i/10.0 for i in range(6,10)],\n",
    "    'colsample_bytree':[i/10.0 for i in range(6,10)],\n",
    "    'n_estimators':[10, 100, 1000]\n",
    "}\n",
    "\n",
    "gsearch = GridSearchCV(estimator = xgboost.XGBClassifier(\n",
    "    tree_method='gpu_hist',\n",
    "    gpu_id=0, \n",
    "    use_label_encoder = False, \n",
    "    eval_metric='mlogloss',\n",
    "    learning_rate = 0.1,\n",
    "    n_estimators = 10,\n",
    "    max_depth = 5,\n",
    "    min_child_weight = 1,\n",
    "    gamma = 0,\n",
    "    subsample = 0.8,\n",
    "    colsample_bytree = 0.8),\n",
    "        param_grid = param_test,\n",
    "        scoring = 'accuracy',\n",
    "        n_jobs = 8,\n",
    "        cv = 5, \n",
    "        verbose = 2)\n",
    "\n",
    "gsearch.fit(X_train, y_train)\n",
    "\n",
    "# gsearch.cv_results_, \n",
    "gsearch.best_params_, gsearch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Fitting\n",
    "\n",
    "model = xgboost.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    tree_method='gpu_hist', \n",
    "    gpu_id=0, \n",
    "    use_label_encoder = False, \n",
    "    eval_metric='auc',\n",
    "    learning_rate = 0.3,\n",
    "    n_estimators = 2000,\n",
    "    max_depth = 6,\n",
    "    min_child_weight = 5,\n",
    "    gamma = 0.5,\n",
    "    subsample = 0.9,\n",
    "    colsample_bytree = 0.9)\n",
    "\n",
    "model.fit(X_train, y_train, eval_set = [(X_test, y_test)], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation and shap summary plot\n",
    "\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "shap.summary_plot(shap_values, X_train, max_display=20, feature_names=feature_names)\n",
    "\n",
    "modelEvaluation(X_test, y_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract top 10 features\n",
    "\n",
    "importance = np.average(np.abs(shap_values),0)\n",
    "\n",
    "sorted_indices = importance.argsort()[::-1]  # Sort indices in descending order\n",
    "top_10_indices = sorted_indices[:10]  # Select the top 10 indices\n",
    "\n",
    "top_10_features = X_train.iloc[0,top_10_indices].index  # Assuming X_train is your feature matrix\n",
    "\n",
    "print(top_10_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with top 10 features\n",
    "\n",
    "X_reduced_train = X_train.iloc[:, top_10_indices]\n",
    "X_reduced_test = X_test.iloc[:, top_10_indices]\n",
    "\n",
    "model.fit(X_reduced_train, y_train, eval_set = [(X_reduced_test, y_test)], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation and shap summary plot with top 10 features\n",
    "\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_reduced_train)\n",
    "shap.summary_plot(shap_values, X_reduced_train, max_display=10, feature_names=top_10_features)\n",
    "\n",
    "modelEvaluation(X_reduced_test, y_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_reduced_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "compoundName = db['name']\n",
    "compoundList = compoundName[y_test.index].values\n",
    "predictionResult = pd.DataFrame(list(zip(compoundList, y_test, y_pred)),columns=['Name', 'Truth', 'Prediction'] ).sort_values('Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionResult.to_csv(\"predictionResult.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NU_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
